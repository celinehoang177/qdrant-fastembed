{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model with Transformers and Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of actual dimensions:  112\n",
      "SPLADE BOW rep:\n",
      " [('manhattan', 2.32), ('atomic', 1.74), ('ny', 1.71), ('project', 1.7), ('1945', 1.65), ('war', 1.54), ('legacy', 1.52), ('peaceful', 1.49), ('bomb', 1.48), ('end', 1.19), ('helped', 1.09), ('impact', 1.07), ('bring', 1.06), ('energy', 1.05), ('ii', 1.02), ('was', 1.0), ('nuclear', 0.96), ('bringing', 0.96), ('purpose', 0.93), ('contribution', 0.88), ('history', 0.82), ('atom', 0.81), ('ended', 0.8), ('help', 0.79), ('use', 0.78), ('projects', 0.74), ('science', 0.73), ('york', 0.71), ('fought', 0.69), ('electricity', 0.64), ('wars', 0.6), ('used', 0.57), ('because', 0.55), ('assisted', 0.55), ('brought', 0.54), ('invented', 0.54), ('affect', 0.53), ('scientific', 0.51), ('heritage', 0.46), ('ending', 0.44), ('peace', 0.43), ('benefit', 0.41), ('aided', 0.41), ('holocaust', 0.4), ('happened', 0.4), ('power', 0.38), ('scientists', 0.38), ('1940s', 0.37), ('safe', 0.37), ('important', 0.37), ('effect', 0.37), ('1946', 0.36), ('supported', 0.36), ('motivation', 0.36), ('started', 0.35), ('invention', 0.34), ('explosion', 0.34), ('continued', 0.34), ('reason', 0.34), ('had', 0.33), ('goal', 0.32), ('descendant', 0.29), ('army', 0.28), ('impacts', 0.28), ('broadway', 0.27), ('mission', 0.27), ('radiation', 0.26), ('continue', 0.24), ('historical', 0.23), ('stalin', 0.22), ('usher', 0.22), ('served', 0.22), ('built', 0.22), ('bronx', 0.21), ('contributed', 0.19), ('advantage', 0.19), ('stop', 0.18), ('cause', 0.17), ('era', 0.16), ('bombs', 0.16), ('helping', 0.15), ('didn', 0.14), ('descendants', 0.14), ('gun', 0.13), ('roosevelt', 0.12), ('benefits', 0.12), ('importance', 0.11), ('1950', 0.11), ('death', 0.1), ('us', 0.1), ('wwii', 0.1), ('wrote', 0.1), ('beneficial', 0.09), ('experiment', 0.09), ('japan', 0.09), ('nazi', 0.08), ('headquarters', 0.07), ('fuel', 0.06), ('its', 0.05), ('influenced', 0.05), ('uses', 0.05), ('decisive', 0.05), ('radioactive', 0.05), ('justified', 0.04), ('worked', 0.04), ('achievements', 0.04), ('significance', 0.04), ('facilitated', 0.04), ('pioneer', 0.03), ('technology', 0.02), ('memorial', 0.01), ('sparked', 0.01)]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = AutoTokenizer.from_pretrained('nirantk/Splade_PP_en_v1')\n",
    "reverse_voc = {v: k for k, v in tokenizer.vocab.items()}\n",
    "model = AutoModelForMaskedLM.from_pretrained('nirantk/Splade_PP_en_v1')\n",
    "model.to(device)\n",
    "\n",
    "sentence = \"\"\"The Manhattan Project and its atomic bomb helped bring an end to World War II. Its legacy of peaceful uses of atomic energy continues to have an impact on history and science.\"\"\"\n",
    "\n",
    "inputs = tokenizer(sentence, return_tensors='pt')\n",
    "inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "input_ids = inputs['input_ids']\n",
    "\n",
    "attention_mask = inputs['attention_mask']\n",
    "\n",
    "outputs = model(**inputs)\n",
    "\n",
    "logits, attention_mask = outputs.logits, attention_mask\n",
    "relu_log = torch.log(1 + torch.relu(logits))\n",
    "weighted_log = relu_log * attention_mask.unsqueeze(-1)\n",
    "max_val, _ = torch.max(weighted_log, dim=1)\n",
    "vector = max_val.squeeze()\n",
    "\n",
    "\n",
    "cols = vector.nonzero().squeeze().cpu().tolist()\n",
    "print(\"number of actual dimensions: \", len(cols))\n",
    "weights = vector[cols].cpu().tolist()\n",
    "\n",
    "d = {k: v for k, v in zip(cols, weights)}\n",
    "sorted_d = {k: v for k, v in sorted(d.items(), key=lambda item: item[1], reverse=True)}\n",
    "bow_rep = []\n",
    "for k, v in sorted_d.items():\n",
    "    bow_rep.append((reverse_voc[k], round(v,2)))\n",
    "\n",
    "print(\"SPLADE BOW rep:\\n\", bow_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd0d1bfe0e94495935b38968c1ceb1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66086a40eee447d937d0e4645a0782e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/nirantk/SPLADE_PP_en_v1/commit/2dd283217bc877464d9d951a201f649a13d47c14', commit_message='Upload BertForMaskedLM', commit_description='', oid='2dd283217bc877464d9d951a201f649a13d47c14', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.push_to_hub(\"nirantk/SPLADE_PP_en_v1\", token=\"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\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export with output_attentions and logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting model to models/nirantk_SPLADE_PP_en_v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Framework not specified. Using pt to export the model.\n",
      "Automatic task detection to fill-mask (possible synonyms are: masked-lm).\n",
      "Using the export variant default. Available variants are:\n",
      "    - default: The default ONNX variant.\n",
      "Using framework PyTorch: 2.2.0\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> False\n",
      "Validating ONNX model models/nirantk_SPLADE_PP_en_v1/model.onnx...\n",
      "\t-[✓] ONNX model output names match reference model (logits)\n",
      "\t- Validating ONNX Model output \"logits\":\n",
      "\t\t-[✓] (2, 16, 30522) matches (2, 16, 30522)\n",
      "\t\t-[✓] all values close (atol: 0.0001)\n",
      "The ONNX export succeeded and the exported model was saved at: models/nirantk_SPLADE_PP_en_v1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from optimum.exporters.onnx import main_export\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"nirantk/SPLADE_PP_en_v1\"\n",
    "output_dir = f\"models/{model_id.replace('/', '_')}\"\n",
    "model_kwargs = {\"output_attentions\": True, \"return_dict\": True}\n",
    "\n",
    "print(f\"Exporting model to {output_dir}\")\n",
    "main_export(model_id, output=output_dir, no_post_process=True, model_kwargs=model_kwargs, token = \"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\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
