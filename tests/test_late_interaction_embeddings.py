import numpy as np

from fastembed.late_interaction.late_interaction_text_embedding import (
    LateInteractionTextEmbedding,
)

# vectors are abridged and rounded for brevity
CANONICAL_COLUMN_VALUES = {
    "colbert-ir/colbertv2.0": np.array(
        [
            [0.0759, 0.0841, -0.0299, 0.0374, 0.0254],
            [0.0005, -0.0163, -0.0127, 0.2165, 0.1517],
            [-0.0257, -0.0575, 0.0135, 0.2202, 0.1896],
            [0.0846, 0.0122, 0.0032, -0.0109, -0.1041],
            [0.0477, 0.1078, -0.0314, 0.016, 0.0156],
        ]
    ),
    "answerdotai/answerai-colbert-small-v1": np.array(
        [
            [
                -0.07280886918306351,
                0.046324968338012695,
                -0.04711456969380379,
                0.007616814691573381,
                -0.07374367862939835,
            ],
            [
                -0.04463830217719078,
                0.04426327347755432,
                -0.0740019679069519,
                0.018013158813118935,
                -0.05233371630311012,
            ],
            [
                0.09935862571001053,
                -0.0512261725962162,
                -0.04924933612346649,
                -0.05275791510939598,
                -0.08944497257471085,
            ],
            [
                0.01644221693277359,
                0.02030055969953537,
                -0.037892457097768784,
                0.03164910897612572,
                -0.06501225382089615,
            ],
            [
                -0.07280952483415604,
                0.04632542282342911,
                -0.04711412638425827,
                0.007620019838213921,
                -0.0737423449754715,
            ],
        ]
    ),
}

CANONICAL_QUERY_VALUES = {
    "colbert-ir/colbertv2.0": np.array(
        [
            [0.0824, 0.0872, -0.0324, 0.0418, 0.024],
            [-0.0007, -0.0154, -0.0113, 0.2277, 0.1528],
            [-0.0251, -0.0565, 0.0136, 0.2236, 0.1838],
            [0.0848, 0.0056, 0.0041, -0.0036, -0.1032],
            [0.0574, 0.1072, -0.0332, 0.0233, 0.0209],
            [0.1041, 0.0364, -0.0058, -0.027, -0.0704],
            [0.106, 0.0371, -0.0055, -0.0339, -0.0719],
            [0.1063, 0.0363, 0.0014, -0.0334, -0.0698],
            [0.112, 0.036, 0.0026, -0.0355, -0.0675],
            [0.1184, 0.0441, 0.0166, -0.0169, -0.0244],
            [0.1033, 0.035, 0.0183, 0.0475, 0.0612],
            [-0.0028, -0.014, -0.016, 0.2175, 0.1537],
            [0.0547, 0.0219, -0.007, 0.1748, 0.1154],
            [-0.001, -0.0184, -0.0112, 0.2197, 0.1523],
            [-0.0012, -0.0149, -0.0119, 0.2147, 0.152],
            [-0.0186, -0.0239, -0.014, 0.2196, 0.156],
            [-0.017, -0.0232, -0.0108, 0.2212, 0.157],
            [-0.0109, -0.0024, -0.003, 0.1972, 0.1391],
            [0.0898, 0.0219, -0.0255, 0.0734, -0.0096],
            [0.1143, 0.015, -0.022, 0.0417, -0.0421],
            [0.1056, 0.0091, -0.0137, 0.0129, -0.0619],
            [0.0234, 0.004, -0.0285, 0.1565, 0.0883],
            [-0.0037, -0.0079, -0.0204, 0.1982, 0.1502],
            [0.0988, 0.0377, 0.0226, 0.0309, 0.0508],
            [-0.0103, -0.0128, -0.0035, 0.2114, 0.155],
            [-0.0103, -0.0184, -0.011, 0.2252, 0.157],
            [-0.0033, -0.0292, -0.0097, 0.2237, 0.1607],
            [-0.0198, -0.0257, -0.0193, 0.2265, 0.165],
            [-0.0227, -0.0028, -0.0084, 0.1995, 0.1306],
            [0.0916, 0.0185, -0.0186, 0.0173, -0.0577],
            [0.1022, 0.0228, -0.0174, -0.0102, -0.065],
            [0.1043, 0.0231, -0.0144, -0.0246, -0.067],
        ]
    ),
    "answerdotai/answerai-colbert-small-v1": np.array(
        [
            [
                -0.07284381985664368,
                0.046566370874643326,
                -0.04745578393340111,
                0.007862836122512817,
                -0.07342172414064407,
            ],
            [
                -0.047303810715675354,
                0.04615122452378273,
                -0.07551278918981552,
                0.015907198190689087,
                -0.05169893056154251,
            ],
            [
                0.09658417850732803,
                -0.050601616501808167,
                -0.045930661261081696,
                -0.05225379392504692,
                -0.09086287021636963,
            ],
            [
                0.018151696771383286,
                0.016499565914273262,
                -0.03365525230765343,
                0.03213629126548767,
                -0.07019350677728653,
            ],
            [
                -0.07284455746412277,
                0.046566739678382874,
                -0.0474553257226944,
                0.007866008207201958,
                -0.07342034578323364,
            ],
            [
                -0.07747597992420197,
                0.04492546617984772,
                -0.05500147491693497,
                0.00481201708316803,
                -0.04859568178653717,
            ],
            [
                -0.08030019700527191,
                0.04228733107447624,
                -0.05889962986111641,
                0.0037854709662497044,
                -0.04505941644310951,
            ],
            [
                -0.0847708135843277,
                0.0372406505048275,
                -0.06162143871188164,
                0.005782351363450289,
                -0.045535165816545486,
            ],
            [
                -0.0839170515537262,
                0.038051772862672806,
                -0.06201940029859543,
                0.008990244008600712,
                -0.040899474173784256,
            ],
            [
                -0.07945145666599274,
                0.04162662476301193,
                -0.06150709092617035,
                0.005689332727342844,
                -0.044316913932561874,
            ],
            [
                -0.0846918597817421,
                0.039848651736974716,
                -0.05764637887477875,
                0.004851527977734804,
                -0.044851597398519516,
            ],
            [
                -0.08306191116571426,
                0.04111386090517044,
                -0.05773551017045975,
                0.005829488858580589,
                -0.043249454349279404,
            ],
            [
                -0.08244220912456512,
                0.045967597514390945,
                -0.05841715633869171,
                0.004332489799708128,
                -0.04024769365787506,
            ],
            [
                -0.08384883403778076,
                0.04745207354426384,
                -0.05844803526997566,
                0.004691521171480417,
                -0.04001536965370178,
            ],
            [
                -0.08402004092931747,
                0.05014242231845856,
                -0.05941291153430939,
                0.006919472012668848,
                -0.03451720252633095,
            ],
            [
                -0.08303389698266983,
                0.056932233273983,
                -0.05700742080807686,
                0.005039925221353769,
                -0.035648513585329056,
            ],
            [
                -0.08216217905282974,
                0.05516009032726288,
                -0.056870121508836746,
                0.0057042320258915424,
                -0.037479251623153687,
            ],
            [
                -0.08051314204931259,
                0.05751146003603935,
                -0.05646609142422676,
                0.002825659466907382,
                -0.03645350784063339,
            ],
            [
                -0.08171530812978745,
                0.05607696995139122,
                -0.060637619346380234,
                0.002523677656427026,
                -0.035329170525074005,
            ],
            [
                -0.08073416352272034,
                0.061442479491233826,
                -0.06372791528701782,
                0.009351451881229877,
                -0.03153626620769501,
            ],
            [
                -0.06651420146226883,
                0.06696950644254684,
                -0.067691370844841,
                0.017166925594210625,
                -0.0336877815425396,
            ],
            [
                -0.06525875627994537,
                0.06930849701166153,
                -0.06934580951929092,
                0.013902319595217705,
                -0.03702286258339882,
            ],
            [
                -0.05435023829340935,
                0.058290306478738785,
                -0.06593424826860428,
                0.017084915190935135,
                -0.04559050500392914,
            ],
            [
                -0.03647681698203087,
                0.05234182998538017,
                -0.06759494543075562,
                0.020570268854498863,
                -0.05053173378109932,
            ],
            [
                -0.03461436927318573,
                0.050317905843257904,
                -0.06746530532836914,
                0.022161055356264114,
                -0.05209151282906532,
            ],
            [
                -0.03443999961018562,
                0.04835467040538788,
                -0.0681186318397522,
                0.022960346192121506,
                -0.05275602638721466,
            ],
            [
                -0.03291662037372589,
                0.04853289946913719,
                -0.06811497360467911,
                0.023484041914343834,
                -0.053032271564006805,
            ],
            [
                -0.033493004739284515,
                0.047833025455474854,
                -0.06845826655626297,
                0.023927660658955574,
                -0.05334211513400078,
            ],
            [
                -0.03484959155321121,
                0.046771712601184845,
                -0.06825603544712067,
                0.023615192621946335,
                -0.05325709283351898,
            ],
            [
                -0.03408340737223625,
                0.04744367301464081,
                -0.06930916011333466,
                0.023016896098852158,
                -0.052879709750413895,
            ],
            [
                -0.03444499894976616,
                0.04837885871529579,
                -0.06945264339447021,
                0.02132566086947918,
                -0.05277208611369133,
            ],
            [
                -0.034726064652204514,
                0.047921035438776016,
                -0.07032673060894012,
                0.021958548575639725,
                -0.0531373992562294,
            ],
        ]
    ),
}

docs = ["Hello World"]


def test_batch_embedding():
    docs_to_embed = docs * 10

    for model_name, expected_result in CANONICAL_COLUMN_VALUES.items():
        print("evaluating", model_name)
        model = LateInteractionTextEmbedding(model_name=model_name)
        result = list(model.embed(docs_to_embed, batch_size=6))

        for value in result:
            token_num, abridged_dim = expected_result.shape
            assert np.allclose(value[:, :abridged_dim], expected_result, atol=10e-3), print(
                np.abs(value[:, :abridged_dim] - expected_result)
            )


def test_single_embedding():
    docs_to_embed = docs

    for model_name, expected_result in CANONICAL_COLUMN_VALUES.items():
        print("evaluating", model_name)
        model = LateInteractionTextEmbedding(model_name=model_name)
        result = next(iter(model.embed(docs_to_embed, batch_size=6)))
        token_num, abridged_dim = expected_result.shape
        assert np.allclose(result[:, :abridged_dim], expected_result, atol=10e-4)


def test_single_embedding_query():
    queries_to_embed = docs

    for model_name, expected_result in CANONICAL_QUERY_VALUES.items():
        print("evaluating", model_name)
        model = LateInteractionTextEmbedding(model_name=model_name)
        result = next(iter(model.query_embed(queries_to_embed)))
        token_num, abridged_dim = expected_result.shape
        assert np.allclose(result[:, :abridged_dim], expected_result, atol=10e-4)


def test_parallel_processing():
    model = LateInteractionTextEmbedding(model_name="colbert-ir/colbertv2.0")
    token_dim = 128
    docs = ["hello world", "flag embedding"] * 100
    embeddings = list(model.embed(docs, batch_size=10, parallel=2))
    embeddings = np.stack(embeddings, axis=0)

    embeddings_2 = list(model.embed(docs, batch_size=10, parallel=None))
    embeddings_2 = np.stack(embeddings_2, axis=0)

    embeddings_3 = list(model.embed(docs, batch_size=10, parallel=0))
    embeddings_3 = np.stack(embeddings_3, axis=0)

    assert embeddings.shape[0] == len(docs) and embeddings.shape[-1] == token_dim
    assert np.allclose(embeddings, embeddings_2, atol=1e-3)
    assert np.allclose(embeddings, embeddings_3, atol=1e-3)
